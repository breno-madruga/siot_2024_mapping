{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the datasets of publications related to the Tiny GenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries.\n",
    "import csv, re, pandas as pd, numpy as np\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining the required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function \"clean_title\".\n",
    "def clean_title(title):\n",
    "    if len(title) == 1 and title in punctuation:\n",
    "        return None\n",
    "    title = title.lower()\n",
    "    title = title.replace(\"€\", \"\").replace(\"…\", \"...\").replace(\"τhe\", \"the\").replace(\n",
    "        \"–\", \"-\").replace(\"‘\", \"'\").replace(\"“\", \"\\\"\").replace(\"”\", \"\\\"\").replace(\n",
    "        \"′\", \"'\").replace(\"’\", \"'\").replace(\"č\", \"c\")\n",
    "    while title[0] in punctuation or title[0] == \" \" or title[-1] in punctuation:\n",
    "        if title[0] in punctuation:\n",
    "            title = title[1:]\n",
    "        if title[-1] in punctuation:\n",
    "            title = title[:-1]\n",
    "        title = title.strip()\n",
    "    return re.sub(r\"\\\"+\", \"\", re.sub(r\"\\s+\", \" \", title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting and preprocessing the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Web of Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data.\n",
    "df_wos = pd.read_csv(\"../data/prepared/wos_tiny_genai.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataframe.\n",
    "df_wos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizing the information of dataset.\n",
    "df_wos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the \"None\" value for the \"NaN\" values.\n",
    "df_wos.replace({np.nan: None}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the type of features.\n",
    "df_wos.loc[df_wos.auth_keywords.notnull(), \"auth_keywords\"] = df_wos.loc[\n",
    "    df_wos.auth_keywords.notnull(), \"auth_keywords\"].apply(eval)\n",
    "df_wos.loc[df_wos.authors.notnull(), \"authors\"] = df_wos.loc[\n",
    "    df_wos.authors.notnull(), \"authors\"].apply(eval)\n",
    "df_wos.loc[df_wos.affiliations.notnull(), \"affiliations\"] = df_wos.loc[\n",
    "    df_wos.affiliations.notnull(), \"affiliations\"].apply(eval)\n",
    "df_wos.loc[df_wos.subject_areas.notnull(), \"subject_areas\"] = df_wos.loc[\n",
    "    df_wos.subject_areas.notnull(), \"subject_areas\"].apply(eval)\n",
    "df_wos.publication_date = pd.to_datetime(df_wos.publication_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the feature \"source\".\n",
    "df_wos[\"source\"] = \"Web of Science\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the feature \"title\".\n",
    "df_wos.loc[df_wos.title.notnull(), \"title\"] = df_wos.loc[\n",
    "    df_wos.title.notnull(), \"title\"].apply(clean_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataframe.\n",
    "df_wos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizing the information of dataset.\n",
    "df_wos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Scopus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data.\n",
    "df_scopus = pd.read_csv(\"../data/prepared/scopus_tiny_genai.csv\", header=0, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataframe.\n",
    "df_scopus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizing the information of dataset.\n",
    "df_scopus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the \"None\" value for the \"NaN\" values.\n",
    "df_scopus.replace({np.nan: None}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the type of features.\n",
    "df_scopus.auth_keywords.loc[df_scopus.auth_keywords.notnull()] = df_scopus.auth_keywords.loc[\n",
    "    df_scopus.auth_keywords.notnull()].apply(eval)\n",
    "df_scopus.index_terms.loc[df_scopus.index_terms.notnull()] = df_scopus.index_terms.loc[\n",
    "    df_scopus.index_terms.notnull()].apply(eval)\n",
    "df_scopus.affiliations.loc[df_scopus.affiliations.notnull()] = df_scopus.affiliations.loc[\n",
    "    df_scopus.affiliations.notnull()].apply(eval)\n",
    "df_scopus.subject_areas.loc[df_scopus.subject_areas.notnull()] = df_scopus.subject_areas.loc[\n",
    "    df_scopus.subject_areas.notnull()].apply(eval)\n",
    "df_scopus.authors.loc[df_scopus.authors.notnull()] = df_scopus.authors.loc[\n",
    "    df_scopus.authors.notnull()].apply(eval)\n",
    "df_scopus.author_affil.loc[df_scopus.author_affil.notnull()] = df_scopus.author_affil.loc[\n",
    "    df_scopus.author_affil.notnull()].apply(eval)\n",
    "df_scopus.references.loc[df_scopus.references.notnull()] = df_scopus.references.loc[\n",
    "    df_scopus.references.notnull()].apply(eval)\n",
    "df_scopus.publication_date = pd.to_datetime(df_scopus.publication_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the feature \"source\".\n",
    "df_scopus[\"source\"] = \"Scopus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the feature \"title\".\n",
    "df_scopus.title = df_scopus.title.apply(clean_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataframe.\n",
    "df_scopus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizing the information of dataset.\n",
    "df_scopus.info()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merging/Joining the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the duplicated records between Web of Science and Scopus by the features \"title\" and \"doi\".\n",
    "df_wos.id[df_wos.title.isin(df_scopus.title.values) |\n",
    "    df_wos.doi.isin(df_scopus.doi[df_scopus.doi.notnull()].values)].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the missing values of Web of Science's features \"auth_keywords\", \"issn\" and \"doi\" with data from Scopus.\n",
    "filter_data = (df_wos.title.isin(df_scopus.title.values) | df_wos.doi.isin(df_scopus.doi[df_scopus.doi.notnull()].values))\n",
    "df_wos.loc[filter_data & (df_wos.auth_keywords.isnull()), \"auth_keywords\"] = df_wos.loc[\n",
    "    filter_data & (df_wos.auth_keywords.isnull()), [\"title\", \"doi\"]].apply(\n",
    "        lambda x: df_scopus.auth_keywords[(df_scopus.title == x.title) | (df_scopus.doi[\n",
    "            df_scopus.doi.notnull()] == x.doi)].item() if x.doi is not None else \\\n",
    "                df_scopus.auth_keywords[df_scopus.title == x.title].item(), axis=1)\n",
    "df_wos.loc[filter_data & (df_wos.issn.isnull()), \"issn\"] = df_wos.loc[\n",
    "    filter_data & (df_wos.issn.isnull()), [\"title\", \"doi\"]].apply(\n",
    "        lambda x: df_scopus.issn[(df_scopus.title == x.title) | (df_scopus.doi[\n",
    "            df_scopus.doi.notnull()] == x.doi)].item() if x.doi is not None else \\\n",
    "                df_scopus.issn[df_scopus.title == x.title].item(), axis=1)\n",
    "df_wos.loc[(df_wos.title.isin(df_scopus.title.values)) & (df_wos.doi.isnull()), \"doi\"] = df_wos.loc[\n",
    "    (df_wos.title.isin(df_scopus.title.values)) & (df_wos.doi.isnull()), \"title\"].apply(\n",
    "        lambda x: df_scopus.doi[df_scopus.title == x].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the missing values of Scopus' features \"auth_keywords\", \"issn\" and \"publisher\" with data from Web of Science.\n",
    "filter_data = (df_scopus.title.isin(df_wos.title.values) | df_scopus.doi[df_scopus.doi.notnull()].isin(df_wos.doi[df_wos.doi.notnull()].values))\n",
    "df_scopus.loc[filter_data & (df_scopus.auth_keywords.isnull()), \"auth_keywords\"] = df_scopus.loc[\n",
    "    filter_data & (df_scopus.auth_keywords.isnull()), [\"title\", \"doi\"]].apply(\n",
    "        lambda x: df_wos.auth_keywords[(df_wos.title == x.title) | (df_wos.doi[\n",
    "            df_wos.doi.notnull()] == x.doi)].item() if x.doi is not None else \\\n",
    "                df_wos.auth_keywords[df_wos.title == x.title].item(), axis=1)\n",
    "df_scopus.loc[filter_data & (df_scopus.issn.isnull()), \"issn\"] = df_scopus.loc[\n",
    "    filter_data & (df_scopus.issn.isnull()), [\"title\", \"doi\"]].apply(\n",
    "        lambda x: df_wos.issn[(df_wos.title == x.title) | (df_wos.doi[\n",
    "            df_wos.doi.notnull()] == x.doi)].item() if x.doi is not None else \\\n",
    "                df_wos.issn[df_wos.title == x.title].item(), axis=1)\n",
    "df_scopus.loc[filter_data & (df_scopus.publisher.isnull()), \"publisher\"] = df_scopus.loc[\n",
    "    filter_data & (df_scopus.publisher.isnull()), [\"title\", \"doi\"]].apply(\n",
    "        lambda x: df_wos.publisher[(df_wos.title == x.title) | (df_wos.doi[\n",
    "            df_wos.doi.notnull()] == x.doi)].item() if x.doi is not None else \\\n",
    "                df_wos.publisher[df_wos.title == x.title].item(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the duplicated records between Web of Science and Scopus.\n",
    "filter_data = (df_wos.title.isin(df_scopus.title.values) |\n",
    "               df_wos.doi.isin(df_scopus.doi[df_scopus.doi.notnull()].values))\n",
    "df_wos = df_wos[~filter_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizing the final number of records for each dataset.\n",
    "print(\"Web of Science:\", df_wos.id.size)\n",
    "print(\"Scopus:\", df_scopus.id.size)\n",
    "print(\"Expected total number of records for the final dataset:\",\n",
    "      (df_wos.id.size + df_scopus.id.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merging/Joining the datasets.\n",
    "df_final = pd.concat([df_wos, df_scopus], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the \"None\" value for the \"NaN\" values.\n",
    "df_final.replace({np.nan: None}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the feature \"source\".\n",
    "df_final.rename(columns={\"source\": \"data_source\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataframe.\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizing the information of dataset.\n",
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the final dataset to CSV file.\n",
    "df_final.to_csv(\"../data/raw/final_raw.csv\", index=False, quoting=csv.QUOTE_ALL)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f50bd5474255f82aa829301912ce59e29110123be660cf8d7583f66a20371684"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
