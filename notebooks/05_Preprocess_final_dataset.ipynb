{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xVJgbbbtmZGW"},"source":["# Cleaning and Preprocessing the final dataset of publications related to the Tiny GenAI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"ZVNCRW4YmZGZ"},"outputs":[],"source":["# Importing the required libraries.\n","import csv, pandas as pd, numpy as np\n","from datetime import date"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Generating the dataframe from the raw data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"xpKQ9xXYmZGp"},"outputs":[],"source":["# Creating a dataframe from the raw data.\n","df_data = pd.read_csv(\"../data/raw/final_raw.csv\", header=0, dtype=object)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"anb1Lu7GmZGt","outputId":"280aa531-ada0-4ce7-ef93-bce77056aff7","tags":[]},"outputs":[],"source":["# Checking the dataframe.\n","df_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"avdD2KX6mZGz","outputId":"3ef16483-8b14-48eb-f2c2-f46a1a90520c","tags":[]},"outputs":[],"source":["# Visualizing the information of dataset.\n","df_data.info()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g_L-1ZTWmZG4"},"source":["## 2. Cleaning and preprocessing the dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to normalize the affiliations of the authors.\n","def normalize_affiliations(row):\n","    # Getting missing values within the feature \"author_affil\" from \"affiliations\" one.\n","    if row.affiliations and row.author_affil:\n","        for pos, author in enumerate(row.author_affil):\n","            for affil in row.affiliations:\n","                if affil[\"id\"] and author[\"affil_id\"] and affil[\"id\"] in [af.strip()\n","                        for af in author[\"affil_id\"].split(\",\")]:\n","                    row.author_affil[pos][\"affil_id\"] = affil[\"id\"]\n","                    row.author_affil[pos][\"affiliation\"] = affil[\"affiliation\"]\n","                    if affil[\"country\"] and not author[\"country\"]:\n","                        row.author_affil[pos][\"country\"] = affil[\"country\"]\n","                    elif affil[\"country\"] != author[\"country\"]:\n","                        row.author_affil[pos][\"country\"] = affil[\"country\"]\n","    else:\n","        # Getting missing values within the feature \"affiliations\" from \"author_affil\" one.\n","        if row.author_affil:\n","            affils = set([(author[\"affil_id\"], author[\"affiliation\"], author[\"country\"])\n","                          for author in row.author_affil\n","                          if author[\"affil_id\"] or author[\"affiliation\"]])\n","            if len(affils) > 0:\n","                keys = [\"id\", \"affiliation\", \"country\"]\n","                row.affiliations = tuple([dict(zip(keys, affil)) for affil in affils])\n","            else:\n","                row.affiliations = None\n","    return row"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to normalize the name of the authors.\n","def normalize_name_authors(row):\n","    if row.authors and row.author_affil:\n","        for pos, item in enumerate(row.authors):\n","            for author in list(row.author_affil):\n","                if item[\"id\"] == author[\"id\"]:\n","                    row.authors[pos][\"name\"] = author[\"name\"]\n","    elif row.author_affil:\n","        authors = set([(author[\"id\"], author[\"name\"]) for author in row.author_affil\n","                       if author[\"name\"]])\n","        if len(authors) > 0:\n","            keys = [\"id\", \"name\"]\n","            row.authors = tuple([dict(zip(keys, author)) for author in authors])\n","        else:\n","            row.authors = None\n","\n","    return row"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to normalize the the authors and their affiliations.\n","def normalize_features(row):\n","    fields = {\n","        \"authors\": [\"id\", \"name\"],\n","        \"affiliations\": [\"id\", \"affiliation\", \"country\"],\n","        \"affil\": [\"affil_id\", \"affiliation\", \"country\"]\n","    }\n","    # Normalizing the authors.\n","    records = [tuple([item[f] for f in fields[\"authors\"]]) for item in row.authors] \\\n","        if row.authors else []\n","    if row.author_affil:\n","        records = set([*records, *[tuple([item[c] for c in fields[\"authors\"]])\n","                                          for item in row.author_affil\n","                                          if item[\"id\"] and item[\"name\"]]])\n","    elif len(records) > 0 and not row.author_affil:\n","        row.author_affil = tuple([{**dict(zip(fields[\"authors\"], auth)), \"affil_id\": None,\n","                                   \"affiliation\": None, \"country\": None} for auth in records])\n","\n","    if len(records) > 0:\n","        row.authors = tuple([dict(zip(fields[\"authors\"], auth)) for auth in records])\n","\n","    # Normalizing the affiliations.\n","    if row.affiliations:\n","        records = [tuple([item[c] for c in fields[\"affiliations\"]])\n","                          for item in row.affiliations]\n","        if row.author_affil:\n","            records = set([*records, *[tuple([item[c] for c in fields[\"affil\"]])\n","                                              for item in row.author_affil\n","                                              if item[\"affil_id\"] or item[\"affiliation\"]]])\n","        row.affiliations = tuple([dict(zip(fields[\"affiliations\"], affil))\n","                                  for affil in records])\n","    return row"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Defining the \"None\" value for the \"NaN\" values.\n","df_data.replace({np.nan: None}, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Q_-4LljxmZG_"},"outputs":[],"source":["# Changing the type of features.\n","df_data.loc[:, [\"auth_keywords\", \"index_terms\", \"affiliations\", \"subject_areas\", \"authors\", \"references\"]] = \\\n","    df_data.loc[:, [\"auth_keywords\", \"index_terms\", \"affiliations\", \"subject_areas\", \"authors\", \"references\"]].apply(\n","        lambda x: x.apply(lambda y: eval(y) if y else None), axis=1)\n","df_data.loc[df_data.data_source == \"Scopus\", \"author_affil\"] = df_data.loc[\n","    df_data.data_source == \"Scopus\", \"author_affil\"].apply(lambda x: eval(x) if x else None)\n","df_data.publication_date = pd.to_datetime(df_data.publication_date)\n","df_data.year = df_data.year.astype(np.int32)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Fixing the value of the features \"production_type\" and \"source_type\".\n","df_data.loc[df_data.data_source == \"Web of Science\", [\"production_type\", \"source_type\"]] = \\\n","df_data.loc[df_data.data_source == \"Web of Science\", [\"production_type\", \"source_type\"]].apply(\n","    lambda x: pd.Series({\"production_type\": \"Journal\", \"source_type\": \"j\"}) if \"Article\" in x.production_type \\\n","        else pd.Series({\"production_type\": x.production_type, \"source_type\": x.source_type}), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Fixing the value of feature \"language\".\n","df_data.loc[df_data.data_source == \"Web of Science\", \"language\"] = df_data.loc[\n","    df_data.data_source == \"Web of Science\", \"language\"].apply(lambda x: x.lower()[:3])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Defining the \"zero\" value for the articles without numbers of citation and references.\n","df_data.loc[df_data.citation_num.isnull(), \"citation_num\"] = 0\n","df_data.loc[df_data.ref_count.isnull(), \"ref_count\"] = 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Applying the function \"normalize_name_authors\" to the data.\n","df_data.loc[df_data.data_source == \"Scopus\", [\"authors\", \"author_affil\"]] = df_data.loc[\n","    df_data.data_source == \"Scopus\", [\"authors\", \"author_affil\"]].apply(\n","        normalize_name_authors, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Checking if there are the empty lists of authors.\n","df_data.authors[df_data.authors == ()].size"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Applying the function \"normalize_affiliations\" to the data.\n","df_data.loc[df_data.data_source == \"Scopus\", [\"affiliations\", \"author_affil\"]] = df_data.loc[\n","    df_data.data_source == \"Scopus\", [\"affiliations\", \"author_affil\"]].apply(\n","        normalize_affiliations, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Checking if there are the empty lists of affiliations.\n","df_data.affiliations[df_data.affiliations == ()].size"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Applying the function \"normalize_features\" to the data.\n","df_data.loc[df_data.data_source == \"Scopus\", [\"authors\", \"affiliations\", \"author_affil\"]] = df_data.loc[\n","    df_data.data_source == \"Scopus\", [\"authors\", \"affiliations\", \"author_affil\"]].apply(\n","        normalize_features, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Removing the unnecessary columns.\n","cols = [\"language\", \"author_affil\"]\n","df_data.drop(columns=cols, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Checking the distribution of the feature \"production_type\".\n","pd.DataFrame(zip(df_data.production_type.value_counts(dropna=False).index,\n","                 df_data.source_type.value_counts(dropna=False).index,\n","                 df_data.production_type.value_counts(dropna=False).values\n","                 ), columns=[\"Production Type\", \"Source Type\", \"Quantity\"]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Applying the exclusion criteria.\n","df_data = df_data[df_data.year >= 2019]\n","df_data = df_data[df_data.abstract.notnull()]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Defining the \"None\" value for the \"NaN\" values.\n","df_data.replace({np.nan: None}, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"4vPzqPp3mZHc","outputId":"2d18e9a7-ca4c-40ba-a264-5e5b4251f308","tags":[]},"outputs":[],"source":["# Checking the dataframe.\n","df_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["# Visualizing the information of dataset.\n","df_data.info()"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Saving the dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Exporting the data to CSV file.\n","df_data.to_csv(\"../data/prepared/final_tiny_genai.csv\", index=False, quoting=csv.QUOTE_ALL)"]}],"metadata":{"colab":{"collapsed_sections":["35ZpeibMmZIz"],"name":"grupo-1.ipynb","provenance":[]},"file_extension":".py","interpreter":{"hash":"f50bd5474255f82aa829301912ce59e29110123be660cf8d7583f66a20371684"},"kernelspec":{"display_name":"Python 3.8.5 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"mimetype":"text/x-python","name":"python","npconvert_exporter":"python","orig_nbformat":2,"pygments_lexer":"ipython3","version":3},"nbformat":4,"nbformat_minor":2}
